{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo de K-medias"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El algortimo de k-medias consiste en el agrupamiento particional de puntos en un espacio a partir de su distancia (en este espacio) bajo una métrica dada. Para esto, creemos un modelo distribucional simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  2.  1.  1.  2.  2.  2.  2.]\n",
      " [ 2.  0.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  0.  1.  1.  0.  0.  0.]\n",
      " [ 1.  1.  1.  0.  1.  0.  0.  0.]\n",
      " [ 2.  1.  1.  1.  0.  1.  1.  1.]\n",
      " [ 2.  1.  0.  0.  1.  0.  2.  2.]\n",
      " [ 2.  1.  0.  0.  1.  2.  0.  2.]\n",
      " [ 2.  1.  0.  0.  1.  2.  2.  0.]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "sentences = ['el gato juega con el perro', 'el carro atropeya al perro', 'el carro atropeya al gato']\n",
    "\n",
    "def vocab():\n",
    "    dicc = defaultdict()\n",
    "    dicc.default_factory = lambda: len(dicc)\n",
    "    return dicc\n",
    "\n",
    "def BoW(corpus,vocab):\n",
    "    for w in corpus:\n",
    "        yield[vocab[w_i] for w_i in w.split()]\n",
    "        \n",
    "words = vocab()\n",
    "BagOfWords = list(BoW(sentences,words))\n",
    "\n",
    "A = np.zeros((len(words),len(words)))\n",
    "for w1 in words:\n",
    "    for w2 in words:\n",
    "        cooc = 0\n",
    "        for context in BagOfWords:\n",
    "            if words[w1] in context and words[w2] in context and w1 != w2:\n",
    "                cooc += 1\n",
    "        A[words[w1],words[w2]] = cooc\n",
    "    \n",
    "print A"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Por ejemplo, podemos comparar la distancia euclideana entre los puntos \"gato\" y \"perro\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41421356237\n"
     ]
    }
   ],
   "source": [
    "def eucl(x,y):\n",
    "    return np.linalg.norm(x-y)\n",
    "\n",
    "print eucl(A[words['gato']],A[words['perro']])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El algoritmo de K-medias tomará estos vectores y les asignará un grupo iterativamente, para esto deben asignarse k centroides aleatoriamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0], [2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0]]\n"
     ]
    }
   ],
   "source": [
    "def centroids(X, cents, k):\n",
    "    for cluster in range(0, k):\n",
    "        cents.append(X[np.random.randint(0, len(X), size=1)].flatten().tolist())\n",
    " \n",
    "    return cents\n",
    "\n",
    "k = 2\n",
    "centroides = []\n",
    "print centroids(A,centroides,k)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ahora, necesitamos definir una función que regrese un cluster dado las distancias mínimas entre los centroides y los puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['juega', 'gato', 'perro', 'con']\n",
      "['el', 'al', 'carro', 'atropeya']\n"
     ]
    }
   ],
   "source": [
    "def min_dist(X, centroids):\n",
    "    C = [[] for i in range(k)]\n",
    "    for x in X:\n",
    "        mu_index = min( [(i[0], eucl(A[words[x]],centroids[i[0]])) for i in enumerate(centroids)], key=lambda t:t[1] )[0]\n",
    "        try:\n",
    "            C[mu_index].append(x)\n",
    "        except KeyError:\n",
    "            C[mu_index] = [x]\n",
    "        \n",
    "    for cluster in C:\n",
    "        if not cluster:\n",
    "            cluster.append(X[np.random.randint(0, len(X), size=1)].flatten().tolist())\n",
    " \n",
    "    return C\n",
    "\n",
    "\n",
    "\n",
    "C = min_dist(words, centroides)\n",
    "\n",
    "for c in C:\n",
    "    print c"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En este caso, sólo \"juega\" entra en unclúster diferente. Mientras que todas las otras palabras se agurpan en otro cluster. Sin embargo, el algoritmo correrá hasta que en el paso n+1 no se hagan asignaciones distintas del paso n. Por tanto debemos definir una variable que nos haga posible comparar los centroides en ambos pasos.\n",
    "\n",
    "En cada paso se reasignarán los centroides. Un nuevo centroide será el punto medio entre los puntos de cada clúster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['juega', 'gato', 'perro', 'con'], ['el', 'al', 'carro', 'atropeya']]\n"
     ]
    }
   ],
   "source": [
    "centroides_n = [[] for i in range(k)]\n",
    "\n",
    "while centroides != centroides_n:\n",
    "    clusts = min_dist(words, centroides)\n",
    "    \n",
    "    i = 0\n",
    "    for c in C:\n",
    "        centroides_n[i] = centroides[i]\n",
    "        mean = np.zeros(len(words))\n",
    "        for point in c:\n",
    "            mean += (1./len(c))*A[words[point]]\n",
    "        centroides[i] = list(mean)\n",
    "        i += 1\n",
    "print clusts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Final mente, los clústers obtenidos agrupan a \"gato\", \"perro\", \"juega\" y \"con\" en un sólo grupo. El algoritmo, empero, es no determinístico. Es decir, el arupamiento puede variar en diferentes corridas. Esto debido a que la asignación de los centroides se hace aleatoriamente. En todo caso, se puede hacer una asignación de los centroides fijando siempre dos puntos. Sin embargo, se corre el riesgo que estos dos puntos no sean los óptimos para inicializar el algoritmo, y, por tanto, puede afectar el agrupamiento final. Otra opción es elegir los puntos más representativos de los datos. Sin embargo, esto implica hacer un análisis previo, que muchas veces se quiere evitar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
