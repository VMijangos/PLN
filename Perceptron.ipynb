{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo del Perceptrón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo del perceptrón aprende los parámetros a partir de la iteración de una especie de gradiente descendiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos la siguiente distribución de los datos. Estos datos son linealmente separables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[1,0],[0,1],[0,0],[1,1]])\n",
    "Y = np.array([1,0,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer sencillo el procesamiento, añadimos una columna más a los datos. Esta columna representa el bias y, por tanto, es siempre igual a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m,n = X.shape   #dimensiones de los datos\n",
    "X1 = np.append(X,np.ones((m,1)),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos los parámetros de forma aleatoria. En este caso, el vector de incio es $w = (1,1)^T$ y el bias es $b = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.ones(n+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, definimos los hiperparámetros. Los hiperparámetros, en este caso son: (1) el rango de aprendizaje; y (2) el número máximo de iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hiperparametros\n",
    "l = 1         #Rango de aprendizaje\n",
    "k = 1000      #Num. maximo de iteraciones\n",
    "\n",
    "#Criterios\n",
    "t = 1         #Iteracion inicial\n",
    "stop = False  #Criterio de paro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos aplicar el algoritmo del perceptron con los hiperparámetros propuestos. En este caso, el algoritmo corre las predicciones de las clases de los datos a partir de los parámetros en ese estado: $$f(x) = \\begin{cases} 1 & \\text{ si } w\\cdot x + b > 0 \\\\  0 & \\text{ si } w\\cdot x + b \\leq 0 \\end{cases}$$\n",
    "\n",
    "Entonces, cada nuevo parámetro se calcula como: $$ w_i \\leftarrow w_i - \\eta (f(x^{(k)}) - y_k) x^{(k)}_i$$\n",
    "\n",
    "En particular, se nota que lo hace por cada uno de los $N$ ejemplos. Entonces, en general, podemos ver que para todos los datos de entrenamiento, el proceso de actualización es:\n",
    "\n",
    "$$w_i \\leftarrow w_i - \\eta \\sum_{k=1}^N(f(x^{(k)}) - y_k) x^{(k)}_i$$\n",
    "\n",
    "El algoritmo se detiene cuando alcanza un error igual a 0 o cuando se ha alcanzado el máximo número de iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado 1 \t prediccion [1 1 1 1] \tparametros [ 1.  0. -1.]\n",
      "Estado 2 \t prediccion [0 0 0 0] \tparametros [ 3.  1.  1.]\n",
      "Estado 3 \t prediccion [1 1 1 1] \tparametros [ 3.  0. -1.]\n",
      "Estado 4 \t prediccion [1 0 0 1] \tparametros [ 3.  0. -1.]\n"
     ]
    }
   ],
   "source": [
    "while  stop == False:\n",
    "    pred = (np.dot(X1,w) > 0).astype(np.int)      #Funcion de prediccion\n",
    "    err =  pred - Y              #Error \n",
    "    w -= l*((X1.T * err).T).sum(0) #Actualizacion de los parametros w\n",
    "    \n",
    "    print 'Estado', t, '\\t prediccion', pred, '\\t',\n",
    "    print 'parametros', w\n",
    "    t += 1\n",
    "    if (pred - Y).sum(0) == 0 or t > k:   #Criterio de paro\n",
    "        stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clasificación final es adecuada. El vector de parámetros es $w = (3, 0)^T$ y el bias es $b=-1$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
